{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Group_face_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU1bF27DF2ZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install face_recognition\n",
        "from imutils import paths\n",
        "import face_recognition\n",
        "import argparse\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n",
        "def encode_images():\n",
        "  # grab the paths to the input images in our dataset\n",
        "  path = \"/content/drive/My Drive/core_project/Data/Trained\"\n",
        "  print(\"[INFO] quantifying faces...\")\n",
        "  imagePaths = list(paths.list_images(path))\n",
        "  print(imagePaths)\n",
        "  # initialize the list of known encodings and known names\n",
        "  knownEncodings = [] \n",
        "  knownNames = []\n",
        "  for (i, imagePath) in enumerate(imagePaths):\n",
        "    # extract the person name from the image path\n",
        "    print(\"[INFO] processing image {}/{}\".format(i + 1,\n",
        "      len(imagePaths)))\n",
        "    name = imagePath.split(os.path.sep)[-2]\n",
        "\n",
        "    # load the input image and convert it from RGB (OpenCV ordering)\n",
        "    # to dlib ordering (RGB)\n",
        "    image = cv2.imread(imagePath)\n",
        "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # detect the (x, y)-coordinates of the bounding boxes\n",
        "    # corresponding to each face in the input image\n",
        "    boxes = face_recognition.face_locations(rgb,\n",
        "      model= \"hog\")\n",
        "\n",
        "    # compute the facial embedding for the face\n",
        "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
        "\n",
        "    # loop over the encodings\n",
        "    for encoding in encodings:\n",
        "      # add each encoding + name to our set of known names and\n",
        "      # encodings\n",
        "      knownEncodings.append(encoding)\n",
        "      knownNames.append(name)\n",
        "  print(\"[INFO] serializing encodings...\")\n",
        "  data = {\"encodings\": knownEncodings, \"names\": knownNames}\n",
        "  f = open(\"/content/drive/My Drive/core_project/encodings.pickle\", \"wb\")\n",
        "  f.write(pickle.dumps(data))\n",
        "  f.close()\n",
        "encode_images()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwL1pZVjP_vA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract and plot each detected face in a photograph\n",
        "!pip install mtcnn\n",
        "%tensorflow_version 1.x\n",
        "# face detection with mtcnn on a photograph\n",
        "# extract and plot each detected face in a photograph\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle\n",
        "from matplotlib.patches import Circle\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from PIL import Image\n",
        "import os\n",
        "import time\n",
        "count = 1\n",
        "def just_crop(filename, result_list, fp):\n",
        "\tglobal count\n",
        "\tfp = fp + \"data\"\n",
        "\ttry:\n",
        "\t\tos.mkdir(fp)\n",
        "\texcept:\n",
        "\t\tprint(\"already created\")\n",
        "\tdata = Image.open(filename)\n",
        "\tx1, y1, width, height = result_list[0]['box']\n",
        "\tx2, y2 = x1 + width, y1 + height\n",
        "\tface = data.crop((x1,y1,x2,y2))\n",
        "\ts = fp + \"/\" + str(count) + \".jpg\"\n",
        "\tface.save(s)\n",
        "\tcount = count+1\n",
        "\t\n",
        "# draw each face separately\n",
        "def extract_faces(filename, result_list):\n",
        "\t# load the image\n",
        "\ttry:\n",
        "\t\tos.mkdir(filename[:-4])\n",
        "\texcept:\n",
        "\t\tprint(\" \")\n",
        "\tdata = Image.open(filename)\n",
        "\t# plot each face as a subplot\n",
        "\tj = 1\n",
        "\tfaces = []\n",
        "\tfor i in range(len(result_list)):\n",
        "\t\t# get coordinates\n",
        "\t\t# print(result_list[i])\n",
        "\t\tx1, y1, width, height = result_list[i]['box']\n",
        "\t\tif(width < 0 and height < 0):\n",
        "\t\t\tcontinue\n",
        "\t\tx2, y2 = x1 + width, y1 + height\n",
        "\t\t# define subplot\n",
        "\t\tface = data.crop((x1,y1,x2,y2))\n",
        "\t\tprint(x1,y1,x2,y2)\n",
        "\t\ts = filename[:-4] + \"/\" + str(j) + \".jpg\"\n",
        "\t\tface.save(s)\n",
        "\t\tj = j+1\n",
        "\t\tfaces.append((y1,x2,y2,x1))\n",
        "\treturn faces\n",
        "\t# \tpyplot.subplot(1, len(result_list), i+1)\n",
        "\t# \tpyplot.axis('off')\n",
        "\t# \t# plot face\n",
        "\t# \tpyplot.imshow(data[y1:y2, x1:x2])\n",
        "\t# # show the plot\n",
        "\t# pyplot.show()\n",
        "def mtcnn_detection(filename,fp):\n",
        "\t# load image from file\n",
        "\tpixels = pyplot.imread(filename)\n",
        "\t# create the detector, using default weights\n",
        "\tdetector = MTCNN()\n",
        "\t# detect faces in the image\n",
        "\tfaces = detector.detect_faces(pixels)\n",
        "\t# display faces on the original image\n",
        "\textract_faces(filename, faces)\n",
        "\t# try:\n",
        "\t# \tjust_crop(filename,faces,fp)\n",
        "\t# except:\n",
        "\t# \tprint(\"This image can be deleted\" + filename)\n",
        "\n",
        "fp = \"/content/drive/My Drive/core_project/Data/Test/\"\n",
        "fn = input(\"enter your file name inside test folder\")\n",
        "faces = mtcnn_detection(fp+fn,fp)\n",
        "# this is only for data finding face in an image\n",
        "# for f in os.walk(fp):\n",
        "# \tprint(\"true1\")\n",
        "# \tfor file in f:\n",
        "# \t\tprint(\"true2\")\n",
        "# \t\tif (type(file) == list and len(file) > 1):\n",
        "# \t\t\tprint(\"true3\")\n",
        "# \t\t\tfor each in file:\n",
        "# \t\t\t\tfilename = fp + each\n",
        "# \t\t\t\tprint(filename)\n",
        "# \t\t\t\tmtcnn_detection(filename,fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baKN2TNyn31h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install face_recognition\n",
        "import face_recognition\n",
        "import pickle\n",
        "import cv2\n",
        "!pip install mtcnn\n",
        "%tensorflow_version 1.x\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.patches import Rectangle\n",
        "from matplotlib.patches import Circle\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from PIL import Image\n",
        "import os\n",
        "%matplotlib inline\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "def extract_faces(filename, result_list):\n",
        "\ttry:\n",
        "\t\tos.mkdir(filename[:-4])\n",
        "\texcept:\n",
        "\t\tprint(\" \")\n",
        "\tdata = Image.open(filename)\n",
        "\tj = 1\n",
        "\tfaces = []\n",
        "\tfor i in range(len(result_list)):\n",
        "\t\t# get coordinates\n",
        "\t\t# print(result_list[i])\n",
        "\t\tx1, y1, width, height = result_list[i]['box']\n",
        "\t\tif(width < 20 and height < 20):\n",
        "\t\t\tcontinue\n",
        "\t\tx2, y2 = x1 + width, y1 + height\n",
        "\t\t# define subplot\n",
        "\t\tface = data.crop((x1,y1,x2,y2))\n",
        "\t\t# print(x1,y1,x2,y2)\n",
        "\t\ts = filename[:-4] + \"/\" + str(j) + \".jpg\"\n",
        "\t\tface.save(s)\n",
        "\t\tj = j+1\n",
        "\t\tfaces.append((y1,x2,y2,x1))\n",
        "\treturn faces\n",
        "\t# \tpyplot.subplot(1, len(result_list), i+1)\n",
        "\t# \tpyplot.axis('off')\n",
        "\t# \t# plot face\n",
        "\t# \tpyplot.imshow(data[y1:y2, x1:x2])\n",
        "\t# # show the plot\n",
        "\t# pyplot.show()\n",
        "def mtcnn_detection(filename,fp):\n",
        "\tpixels = pyplot.imread(filename)\n",
        "\tdetector = MTCNN()\n",
        "\tfaces = detector.detect_faces(pixels)\n",
        "\treturn extract_faces(filename, faces)\n",
        "\t# try:\n",
        "\t# \tjust_crop(filename,faces,fp)\n",
        "\t# except:\n",
        "\t# \tprint(\"This image can be deleted\" + filename)\n",
        "data = pickle.loads(open(\"/content/drive/My Drive/core_project/encodings.pickle\", \"rb\").read())\n",
        "# path = \"/content/drive/My Drive/core_project/Data/Test/\"\n",
        "# filename = path + input(\"enter your file name here: \")\n",
        "fp = \"/content/drive/My Drive/core_project/Data/Test/\"\n",
        "fn = input(\"enter your file name inside test folder\")\n",
        "boxes = mtcnn_detection(fp+fn,fp)\n",
        "image = cv2.imread(fp+fn)\n",
        "rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "encodings = face_recognition.face_encodings(rgb, boxes)\n",
        "\n",
        "names = []\n",
        "\n",
        "for encoding in encodings:\n",
        "\tmatches = face_recognition.compare_faces(data[\"encodings\"],\n",
        "\t\tencoding,0.4)\n",
        "\tname = \"Unknown\"\n",
        "\tif True in matches:\n",
        "\t\tmatchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
        "\t\tcounts = {}\n",
        "\t\tfor i in matchedIdxs:\n",
        "\t\t\tname = data[\"names\"][i]\n",
        "\t\t\tcounts[name] = counts.get(name, 0) + 1\n",
        "\t\tname = max(counts, key=counts.get)\n",
        "\tnames.append(name)\n",
        "print(set(names))\n",
        "for ((top, right, bottom, left), name) in zip(boxes, names):\n",
        "\tcv2.rectangle(image, (left, top), (right, bottom), (255, 0, 255), 2)\n",
        "\ty = top - 15 if top - 15 > 15 else top + 15\n",
        "\tcv2.putText(image, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "\t\t0.75, (255, 0, 0), 2)\n",
        "s = fp+\"out.jpg\"\n",
        "im = Image.fromarray(image)\n",
        "im.save(s)\n",
        "image = plt.imshow(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMktPIRzrGDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install face_recognition\n",
        "import face_recognition\n",
        "import os\n",
        "# Load the jpg files into numpy arrays\n",
        "# biden_image = face_recognition.load_image_file(\"biden.jpg\")\n",
        "# obama_image = face_recognition.load_image_file(\"obama.jpg\")\n",
        "unknown_image = face_recognition.load_image_file(\"/content/drive/My Drive/core_project/1/3.jpg\")\n",
        "known_image = face_recognition.load_image_file(\"/content/drive/My Drive/core_project/1/2.jpg\")\n",
        "\n",
        "\n",
        "path = \"/content/drive/My Drive/core_project/test/occlusions/\"\n",
        "for f in os.walk(path):\n",
        "  for file in f:\n",
        "    if (type(file) == list and len(file) > 0):\n",
        "      for each in file:\n",
        "        filename = path + each\n",
        "        print(filename)\n",
        "        try:\n",
        "          img =  face_recognition.load_image_file(filename)\n",
        "          img = face_recognition.face_encodings(img)[0]\n",
        "        except:\n",
        "          os.remove(filename)\n",
        "\n",
        "\n",
        "# Get the face encodings for each face in each image file\n",
        "# Since there could be more than one face in each image, it returns a list of encodings.\n",
        "# But since I know each image only has one face, I only care about the first encoding in each image, so I grab index 0.\n",
        "# try:\n",
        "#     # biden_face_encoding = face_recognition.face_encodings(biden_image)[0]\n",
        "#     # obama_face_encoding = face_recognition.face_encodings(obama_image)[0]\n",
        "#     known_face_encoding = face_recognition.face_encodings(known_image)[0]\n",
        "#     unknown_face_encoding = face_recognition.face_encodings(unknown_image)[0]\n",
        "# except IndexError:\n",
        "#     print(\"I wasn't able to locate any faces in at least one of the images. Check the image files. Aborting...\")\n",
        "#     quit()\n",
        "\n",
        "# print(type(unknown_face_encoding))\n",
        "# print(unknown_face_encoding.size)\n",
        "# known_faces = [\n",
        "#     known_face_encoding\n",
        "# ]\n",
        "\n",
        "# # # results is an array of True/False telling if the unknown face matched anyone in the known_faces array\n",
        "# results = face_recognition.compare_faces(known_faces, unknown_face_encoding)\n",
        "\n",
        "# print(\"Is the unknown face a picture of Biden? {}\".format(results[0]))\n",
        "# # print(\"Is the unknown face a picture of Obama? {}\".format(results[1]))\n",
        "# print(\"Is the unknown face a new person that we've never seen before? {}\".format(not True in results))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziA1dcW_Reqp",
        "colab_type": "code",
        "outputId": "a603d32e-2089-4c78-fb91-957b18183bfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}